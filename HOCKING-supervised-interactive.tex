\documentclass{beamer}
\usepackage{etex} % to avoid errors http://tex.stackexchange.com/questions/7896/no-room-for-a-new-dimen-when-including-tikz
\usepackage{ulem}
\usepackage{listings}
\usepackage{slashbox}
\usepackage{tikz}
\usepackage[all]{xy}
\usepackage{booktabs}
\usepackage{amsmath,amssymb}
\usepackage{hyperref}
\usepackage{graphicx}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\maximize}{maximize}
\DeclareMathOperator*{\minimize}{minimize}
\newcommand{\sign}{\operatorname{sign}}
\newcommand{\RR}{\mathbb R}
\newcommand{\NN}{\mathbb N}

% Set transparency of non-highlighted sections in the table of
% contents slide.
\setbeamertemplate{section in toc shaded}[default][100]
\AtBeginSection[]
{
  \setbeamercolor{section in toc}{fg=red} 
  \setbeamercolor{section in toc shaded}{fg=black} 
  \begin{frame}
    \tableofcontents[currentsection]
  \end{frame}
}

\begin{document}

\title{Supervised, interactive genomic data analysis}
\author{
Toby Dylan Hocking
}

\date{Barbados workshop, 5--9 January 2015}

\maketitle

\section{Some problems with unsupervised
  DNA copy number analysis}

\begin{frame}
  \frametitle{DNA copy number analysis}

  Figure source: Alberts \textit{et al.} 2002. Molecular Biology of the Cell.
\vskip 0.1in
  \includegraphics[width=\textwidth]{Karyo-both}
\vskip 0.1in
  \begin{minipage}{0.4\linewidth}
    Normal cell with 2 copies of each autosome.
  \end{minipage}
\hskip 0.1\linewidth
  \begin{minipage}{0.4\linewidth}
Cancer cell with many copy number alterations.
  \end{minipage}

\end{frame}

\begin{frame}
  \frametitle{Unsupervised, non-interactive DNA copy number analysis}
  \includegraphics[width=\textwidth]{unlabeled-axes}

  Analyst sees a vector of $d$ noisy data points $\mathbf x\in\RR^d$.

  \vskip 0.1in

  \textbf{Question:}\\
  where are the true changes in copy
  number? (breakpoints)

\end{frame}

\begin{frame}
  \frametitle{Unsupervised, non-interactive DNA copy number analysis}

  \textbf{Unsupervised default model:} 
  fit a breakpoint model $f(\mathbf x, \lambda)$.\\
  ($\lambda$ is a model parameter, for example a p-value threshold or
  the number of breakpoints)

  \begin{displaymath}
  \xymatrix{
    \text{Data $\mathbf x$}
    \ar `[r] [dr] 
    & \text{ }
    \\
    % \text{Plot} \ar@{->}[d]
    & 
    \text{Model $f(\mathbf x, \lambda)$} 
    \\
    % \text{Labels $\mathbf y$}       \ar@{->}[d]
    \\
    \text{Parameter $\lambda$} 
    \ar `r[ruu] [ruu]
    & \text{ }
  }
  \end{displaymath}
  
  \textbf{Problem}: how do we know the model $f$ and parameter
  $\lambda$ are reasonable?

  \vskip 0.1in

  \textbf{Solution:} plot breakpoints $f(\mathbf x, \lambda)$ and
  interactively choose a reasonable parameter $\lambda$.
\end{frame}

\begin{frame}
  \frametitle{Unsupervised, interactive DNA copy number analysis}
  Analyst sees a vector of $d$ noisy data points $\mathbf x\in\RR^d$, \\
  and the model breakpoints $f(\mathbf x, \lambda)$.

  \includegraphics[width=\textwidth]{unlabeled-breakpoints-6}

  Parameter $\lambda$ = 6 breakpoints.
\end{frame}

\begin{frame}
  \frametitle{Unsupervised, interactive DNA copy number analysis}
  Analyst sees a vector of $d$ noisy data points $\mathbf x\in\RR^d$, \\
  and the model breakpoints $f(\mathbf x, \lambda)$.

  \includegraphics[width=\textwidth]{unlabeled-breakpoints-7}

  Parameter $\lambda$ = 7 breakpoints.
\end{frame}

\begin{frame}
  \frametitle{Unsupervised, interactive DNA copy number analysis}
  Analyst sees a vector of $d$ noisy data points $\mathbf x\in\RR^d$, \\
  and the model breakpoints $f(\mathbf x, \lambda)$.

  \includegraphics[width=\textwidth]{unlabeled-breakpoints-8}

  Parameter $\lambda$ = 8 breakpoints.
\end{frame}

\begin{frame}
  \frametitle{Unsupervised, interactive DNA copy number analysis}
  Analyst sees a vector of $d$ noisy data points $\mathbf x\in\RR^d$, \\
  and the model breakpoints $f(\mathbf x, \lambda)$.

  \includegraphics[width=\textwidth]{unlabeled-breakpoints-9}

  Parameter $\lambda$ = 9 breakpoints.
\end{frame}

\begin{frame}
  \frametitle{A brief history of unsupervised DNA copy number analysis}
  \begin{itemize}
  \item GLAD: adaptive weights smoothing (Hup\'e \textit{et al.}, 2004)
  \item DNAcopy: circular binary segmentation (Venkatraman and Olshen,
    2007)
  \item cghFLasso: fused lasso signal approximator with heuristics
    (Tibshirani and Wang, 2007)
  \item HaarSeg: wavelet smoothing (Ben-Yaacov and Eldar, 2008)
  \item GADA: sparse Bayesian learning (Pique-Regi \textit{et al.}, 2008)
  \item flsa: fused lasso signal approximator path algorithm (Hoefling 2009)
  \item cghseg: pruned dynamic programming (Rigaill 2010)
  \item PELT: pruned exact linear time (Killick \textit{et al.}, 2011)
  \end{itemize}
  Demo: \url{http://compbio.med.harvard.edu/CGHweb/}
\end{frame}

\begin{frame}
  \frametitle{Unsupervised, interactive DNA copy number analysis}
  
  Non-interactive unsupervised default model.
  
  \small

  \begin{displaymath}
  \xymatrix{
    \text{Data $\mathbf x$}
    \ar `[r] [dr] 
    %\ar `r[rr] [drr] 
    %\ar `r[rrr] [drrr] 
    %\ar [d]
    & \text{ }
    & \text{ }
    & \text{ }
    \\
    %\text{Plot} 
    %\ar [d]
    & 
    \text{Model $f(\mathbf x, \lambda_1)$} 
    %\ar [r]
    & 
    \textcolor{white}{\text{Plot}}
    %\ar[dd]
    &
    \color{white}{ \text{Model $f(\mathbf x, \lambda_2)$} }
    \\
    %\text{Labels $\mathbf y$}       
    %\ar [d]
    & 
    &
    \\
    \text{Parameter $\lambda_1$} 
    \ar `r[ruu] [ruu]
    %\ar [rr]
    & \text{ }
    & \color{white}{ \text{Parameter $\lambda_2$} }
    %\ar `r[ruu] [ruu] 
  }
  \end{displaymath}
\end{frame}

\begin{frame}
  \frametitle{Unsupervised, interactive DNA copy number analysis}

  Plot the default model.
  
  \small

  \begin{displaymath}
  \xymatrix{
    \text{Data $\mathbf x$}
    \ar `[r] [dr] 
    \ar `r[rr] [drr] 
    %\ar `r[rrr] [drrr] 
    %\ar [d]
    & \text{ }
    & \text{ }
    & \text{ }
    \\
    %\text{Plot} 
    %\ar [d]
    & 
    \text{Model $f(\mathbf x, \lambda_1)$} 
    \ar [r]
    & 
    \text{Plot}
    %\ar[dd]
    &
    \color{white}{ \text{Model $f(\mathbf x, \lambda_2)$} }
    \\
    %\text{Labels $\mathbf y$}       
    %\ar [d]
    & 
    &
    \\
    \text{Parameter $\lambda_1$} 
    \ar `r[ruu] [ruu]
    %\ar [rr]
    & \text{ }
    & \color{white}{ \text{Parameter $\lambda_2$} }
    %\ar `r[ruu] [ruu] 
  }
  \end{displaymath}
\end{frame}

\begin{frame}
  \frametitle{Unsupervised, interactive DNA copy number analysis}

  Increase/decrease parameter based on signal/noise in plot.
  
  \small

  \begin{displaymath}
  \xymatrix{
    \text{Data $\mathbf x$}
    \ar `[r] [dr] 
    \ar `r[rr] [drr] 
    %\ar `r[rrr] [drrr] 
    %\ar [d]
    & \text{ }
    & \text{ }
    & \text{ }
    \\
    %\text{Plot} 
    %\ar [d]
    & 
    \text{Model $f(\mathbf x, \lambda_1)$} 
    \ar [r]
    & 
    \text{Plot}
    \ar[dd]
    &
    \color{white}{ \text{Model $f(\mathbf x, \lambda_2)$} }
    \\
    %\text{Labels $\mathbf y$}       
    %\ar [d]
    & 
    &
    \\
    \text{Parameter $\lambda_1$} 
    \ar `r[ruu] [ruu]
    \ar [rr]
    & \text{ }
    & \text{Parameter $\lambda_2$}
    %\ar `r[ruu] [ruu] 
  }
  \end{displaymath}
\end{frame}

\begin{frame}
  \frametitle{Unsupervised, interactive DNA copy number analysis}

  Fit model using new parameter.
  
  \small

  \begin{displaymath}
  \xymatrix{
    \text{Data $\mathbf x$}
    \ar `[r] [dr] 
    \ar `r[rr] [drr] 
    \ar `r[rrr] [drrr] 
    %\ar [d]
    & \text{ }
    & \text{ }
    & \text{ }
    \\
    %\text{Plot} 
    %\ar [d]
    & 
    \text{Model $f(\mathbf x, \lambda_1)$} 
    \ar [r]
    & 
    \text{Plot}
    \ar[dd]
    &
    \text{Model $f(\mathbf x, \lambda_2)$} 
    \\
    %\text{Labels $\mathbf y$}       
    %\ar [d]
    & 
    &
    \\
    \text{Parameter $\lambda_1$} 
    \ar `r[ruu] [ruu]
    \ar [rr]
    & \text{ }
    & \text{Parameter $\lambda_2$}
    \ar `r[ruu] [ruu] 
  }
  \end{displaymath}
\end{frame}

\begin{frame}
  \frametitle{Summary of unsupervised models, software}

  \begin{center}
  \begin{tabular}{c|c|c}
        & \textbf{unsupervised} & \\
    Evaluation: & qualitative &  \\
    Input: profile $\mathbf x$ + & parameters $\lambda$ &  \\
    \hline
    \textbf{non-interactive}
    & plot $\mathbf x$\\
    fit one model 
    & default parameters &  \\
    & e.g. DNAcopy \\
    \hline
    \textbf{interactive}
    & plot $\mathbf x, f(\mathbf x, \lambda)$\\
    plot, update model 
    & tuned parameters & \\
    & e.g. CGHweb  
  \end{tabular}
  \end{center}

  Works fine for 1 profile, but...

\end{frame}

\begin{frame}
  \frametitle{Unsupervised, interactive DNA copy number analysis\\
  with 3 profiles (in practice we have 1000s)}
  \includegraphics[width=\textwidth]{unlabeled-breakpoints-8}

  Parameter $\lambda_1$ = 8 breakpoints.

  \vskip 0.1in

  \includegraphics[width=\textwidth]{lots-of-breaks}

  Parameter $\lambda_2$ = ??

  \vskip 0.1in

  \includegraphics[width=\textwidth]{only-one-break}

  Parameter $\lambda_3$ = ??

\end{frame}

\begin{frame}
  \frametitle{Some problems with unsupervised analysis}
  \textbf{Training a model that works on many samples and genomic
    regions?} 
  \begin{itemize}
  \item What if we don't have time to look at all samples/regions and
      interactively select a good parameter $\lambda$ for each?
  % \item \textbf{Generalization:} how does the parameter for one
  %   profile $\lambda_1$ help us choose a parameter $\lambda_2, \lambda_3$
  %   for other profiles?
  % \item \textbf{What if we use a different model $g(\mathbf x, \rho)$ where
  %   the learned $\lambda$ is meaningless?
  \item Use default parameter $\lambda$ for all profiles?
  \item If we know a good parameter $\lambda_1=8$ for one profile, 
    does that help us choose a parameter $\lambda_2, \lambda_3$ for
    other profiles?
  \item How does knowledge that $\lambda_1=8$ is good help us train
    another model $g(\mathbf x, \rho)$ with a different parameter
    $\rho$?
  \end{itemize}
  \textbf{Testing different models of the same data?} 
    \begin{itemize}
    \item   Are the breakpoints of $f(\mathbf x, \lambda$) or
  $g(\mathbf x, \rho)$ better?
    \item Plot the data and both models, qualitative visual evaluation?
    \end{itemize}
  All of these problems can be solved by supervised learning.
\end{frame}

\section{Supervised DNA copy number analysis}

\begin{frame}
  \frametitle{Computer vision: look and add labels to...}
  \begin{tabular}{ccc}
    Photos & Cell images & Copy number profiles \\
    \includegraphics[width=1.3in]{faces} &
    \includegraphics[width=1.3in]{cellprofiler} &
    \includegraphics[width=1.5in]{regions-axes}\\
    Labels: faces, names & phenotypes & alterations \\
    CVPR 2013 & CellProfiler & SegAnnDB \\
    246 papers & 873 citations & H, \textit{et al.} 2014. \\
     &
  \end{tabular}
  Sources: \url{http://en.wikipedia.org/wiki/Face_detection}\\
  Jones et al PNAS 2009. Scoring diverse cellular morphologies in
  image-based screens with iterative feedback and machine learning.
\end{frame}

\begin{frame}
  \frametitle{Computer vision for genomic segmentation}
  \begin{center}
  \begin{tabular}{rll}
    \textbf{Breakpoint}\\
 \textbf{detector} & \textbf{strong point} & \textbf{weak point} \\
    \hline
    mathematical  & maximum likelihood & tuning parameters $\lambda$ \\
    models & algorithm finds exact  & chosen using\\
& breakpoint locations  & unrealistic assumptions\\
    \hline
    your eyes & outliers, signal/noise & finding the \\
    & over large regions &  exact breakpoint
  \end{tabular}
  \end{center}
  % \vskip 1cm
  % \textbf{SegAnnDB exploits the strong points of both:}
  % \begin{itemize}
  % \item Plot a maximum likelihood model alongside the data.
  % \item Edit annotated regions.
  % \item The model parameters are automatically updated to agree.
  % \item No tuning parameters, but need to annotate a few profiles.
  % \end{itemize}
  % Demo on \url{http://bioviz.rocq.inria.fr/}

  Discussion of common objections:
  \begin{itemize}
  \item \textbf{Isn't this totally subjective?} Yes, guilty as
    charged. \\
    But so is everything else we do, including choice of
    model $f$ and parameter $\lambda$.
  \item \textbf{Won't the results change based on the annotator?}
    Possibly, but usually annotators agree.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Supervised, non-interactive DNA copy number analysis}

  \includegraphics[width=\textwidth]{regions-axes-full}

  Analyst sees a vector of $d$ noisy data points $\mathbf x\in\RR^d$,\\
  and some manually annotated region labels $\mathbf y$.

  \vskip 0.1in

  \textbf{Question:}\\
    where are the true changes in copy number? (breakpoints)

  \vskip 0.1in

  But wait!

  \vskip 0.1in
  
  I learned in my Statistics 101 class that ``all models are wrong,
  but some are useful.''

\end{frame}

\begin{frame}[fragile]
  \frametitle{Aside: George Box (1919--2013)}
  \small \url{http://www-history.mcs.st-and.ac.uk/Biographies/Box.html}
  \begin{description}
  \item[1919] Born in England, wanted to study chemistry.
  \item[1942] Drafted in WW2, ended up doing statistics.
  \item[1945] Married Jessie Ward.
  \item[1953] PhD advised by Egon Pearson at UCL.
  \item[1959] Married Joan G Fisher. (Ronald Fisher's second daughter)
  \item[1960] Founded Statistics Department at University of Wisconsin.
  \item[1964] Box and Cox, An analysis of transformations (JRSSB).
  \item[1985] Married Claire Louise Quist.
  \item[1987] Box and Draper, \textit{Empirical model-building and
      response surfaces}, page 424:
  \end{description}

  \includegraphics[width=0.8\textwidth]{Box-Draper-all-models-are-wrong-but-some-are-useful-hilite}

  Not the inventor of the box plot! (that was John Tukey, 1970)

\end{frame}

\begin{frame}[fragile]
  \frametitle{Supervised, non-interactive DNA copy number analysis}

  \includegraphics[width=\textwidth]{regions-axes-full}

  Analyst sees a vector of $d$ noisy data points $\mathbf x\in\RR^d$,\\
  and some manually annotated region labels $\mathbf y$.

  \vskip 0.1in

  \sout{\textbf{Question:}\\
    where are the true changes in copy number? (breakpoints)}

  \vskip 0.1in

  ``Essentially, all models are wrong, but some are useful.''\\
  Box and Draper (1987).

  \vskip 0.5cm

  \textbf{Train question:} can we fit a model $f(\mathbf x, \lambda)$
  to the labels $\mathbf y?$
  \\
  \textbf{Test question:} does the fitted model $f(\mathbf x^*, \lambda)$
  have good predictions for test data $\mathbf x^*$ and labels $\mathbf y^*$?

\end{frame}

\begin{frame}
  \frametitle{Supervised training of breakpoint detection model}

  Reference: Hocking \textit{et al.} Learning smoothing models of copy
  number profiles using breakpoint annotations, BMC Bioinfo
  (2013).

  \begin{center}
      \includegraphics[width=0.7\textwidth]{bams-smoothing}
  \end{center}

  Find the best parameter $\lambda$ for $n=6$ profiles $\mathbf x_i$
  with labels $\mathbf y_i$:

  \begin{equation*}
    \hat \lambda = \argmin_{\lambda}
    \sum_{i=1}^n
    E\big[
      \mathbf y_i,
      f(\mathbf x_i, \lambda)
    \big].
  \end{equation*}

  $E$ is zero-one loss (number of incorrect regions).

\end{frame}


\begin{frame}
  \frametitle{Ranking breakpoint detectors by test error}

  Benchmark data set, R package \texttt{neuroblastoma}:
  profiles~$\mathbf x_i$ from 575 neuroblastoma patients, two
  different sets of labels $\mathbf y_i$:
  \begin{description}
  \item[Original] 3418 manually annotated regions (type 0/1 in Excel).
  \item[Detailed] 4359 manually annotated regions (custom GUI).
  \end{description}

  \begin{center}
    \includegraphics[width=0.8\textwidth]{bams-test-error}
  \end{center}

  \begin{description}
  \item[Local model] choose best scalar $\lambda_i$ for each profile $i$.\\
  \item[Global model] choose best scalar $\lambda$ overall.
  \end{description}
\end{frame}

\begin{frame}
  \frametitle{Learning a multi-parameter penalty function}
    \small

  Reference: Rigaill \textit{et al.} Learning sparse penalties for
  change-point detection using max-margin interval regression, ICML
  2013.

    \input{ireg-max-margin}


    \begin{tabular}{rrrrr}
      \hline
      model & parameters & original & detailed & simulation \\ 
      \hline
      BIC &  unsupervised & $7.99 \pm 0.00$ & $13.64 \pm 0.00$ & $11.97 \pm 0.00$ \\ 
      mBIC & unsupervised & $40.99 \pm 0.00$ & $36.88 \pm 0.00$ & $2.25 \pm 0.00$ \\ 
      cghseg.k & 1 & $2.19 \pm 0.82$ & $6.49 \pm 1.16$ & $11.85 \pm 3.52$ \\ 
      log.s.log.d & 3 & $1.90 \pm 0.77$ & $4.72 \pm 0.54$ & $1.50 \pm 1.63$ \\ 
      %L1-reg & 118 &$1.81 \pm 0.58$ & $4.70 \pm 0.88$ & $1.28 \pm 1.47$ \\ 
      \hline
    \end{tabular}

    Percent incorrect labels/regions (mean $\pm$ sd over 10 test sets).

% latex table generated in R 2.15.2 by xtable 1.7-0 package
% Tue Jan 29 11:58:32 2013
\end{frame}

\begin{frame}
  \frametitle{Unsupervised, non-interactive DNA copy number analysis}
  Same as before: unsupervised, non-interactive.
  \begin{displaymath}
  \xymatrix{
    \text{Data $\mathbf x$}
    \ar `[r] [dr] 
    %\ar [d]
    & \text{ }
    \\
    \color{white}{\text{Plot} }
    %\ar [d]
    & 
    \text{Model $f(\mathbf x, \lambda)$} 
    \\
    \color{white}{\text{Labels $\mathbf y$}       }
    %\ar [d]
    \\
    \text{Parameter $\lambda$} 
    \ar `r[ruu] [ruu]
    & \text{ }
  }
  \end{displaymath}
\end{frame}

\begin{frame}
  \frametitle{Supervised, non-interactive DNA copy number analysis}
  Plot data $\mathbf x$, make labels $\mathbf y$, use to train
  parameter $\lambda$.
  \begin{displaymath}
  \xymatrix{
    \text{Data $\mathbf x$}
    \ar `[r] [dr] 
    \ar [d]
    & \text{ }
    \\
    \text{Plot} 
    \ar [d]
    & 
    \text{Model $f(\mathbf x, \lambda)$} 
    \\
    \text{Labels $\mathbf y$}       
    \ar [d]
    \\
    \text{Parameter $\lambda$} 
    \ar `r[ruu] [ruu]
    & \text{ }
  }
  \end{displaymath}
\end{frame}

\begin{frame}
  \frametitle{Supervised analysis uses labels for parameter training}

    \textbf{Unsupervised (interactive).}
  \begin{displaymath}
    \small
  \xymatrix@=0.3cm{
    \text{Data $\mathbf x$}
    \ar `[r] [dr] 
    \ar `r[rr] [drr] 
    \ar `r[rrr] [drrr] 
    %\ar [d]
    & \text{ }
    & \text{ }
    & \text{ }
    \\
    %\text{Plot} 
    %\ar [d]
    & 
    \text{Model $f(\mathbf x, \lambda_1)$} 
    \ar [r]
    & 
    \alert<2>{\text{Plot}}
    \ar[d]
    &
    \text{Model $f(\mathbf x, \lambda_2)$} 
    \\
    \text{Parameter $\lambda_1$}
    \ar `r[ru] [ru]
    \ar [rr]
    & \text{ }
    & \alert<2>{\text{Parameter $\lambda_2$}}
    \ar `r[ru] [ru] \\
    & &   \alert<2>{\text{Plot after modeling.}}
  }
  \end{displaymath}
  
  \textbf{Supervised (non-interactive).}
  \begin{displaymath}
    \small
  \xymatrix@=0.3cm{
    \text{Data $\mathbf x$}
    \ar `[r] [dr] 
    \ar [d]
    & \text{ }
    \\
    \alert<2>{\text{Plot} }
    \ar [d]
    & 
    \text{Model $f(\mathbf x, \lambda)$} 
    \\
    \alert<2>{\text{Labels $\mathbf y$}       }
    \ar [d]
    \\
    \alert<2>{\text{Parameter $\lambda$} }
    \ar `r[ruu] [ruu]
    & \text{ }\\
    \alert<2>{\text{Plot before modeling.}}
  }
\end{displaymath}

\end{frame}

\begin{frame}
  \frametitle{Supervised analysis solves problems, facilitates
    collaboration}
  \textbf{Training a model that works on many samples and genomic
    regions?} 
  \begin{itemize}
  \item Biologist labels $n$ profiles, making a benchmark data set.
  \item Quantitative model training using labels $\mathbf y_i$:
  \begin{equation*}
    \hat \lambda = \argmin_{\lambda}
    \sum_{i=1}^n
    E\big[
      \mathbf y_i,
      f(\mathbf x_i, \lambda)
    \big].
  \end{equation*}
  \item Biologist gets most accurate model $f$ to use on other profiles.
  \end{itemize}
  \textbf{Testing different models of the same data?} 
  \begin{itemize}
  \item Statistician can quantitatively evaluate algorithms using
    zero-one loss $E$ on benchmark data sets.
  \end{itemize}
  But how to make labels $\mathbf y_i$?
\end{frame}

\begin{frame}
  \frametitle{Supervised, interactive copy number analysis}

  Hocking \textit{et al}. SegAnnDB: interactive web-based genomic
  segmentation. Bioinformatics (2014).
  \begin{center}
\includegraphics[width=\textwidth]{new-new-annotations}
  \end{center}
  Analyst sees profile $\mathbf x_i$, model $f(\mathbf x_i, \lambda)$,
  and labels $\mathbf \mathbf y_i$ (editable).

  \vskip 0.1in Public SegAnnDB
  server: \url{http://bioviz.rocq.inria.fr/}

\vskip 0.1in
Demo: private server for McGill data sets.
\small
\url{http://ec2-54-201-171-12.us-west-2.compute.amazonaws.com/}

\end{frame}

\begin{frame}
  \frametitle{Supervised, interactive genomic segmentation}
  First step same as supervised, non-interactive model.
  \small
  \begin{displaymath}
  \xymatrix{
    \text{Data $\mathbf x$}
    \ar `[r] [dr] 
    %\ar `r[rr] [drr] 
    %\ar `r[rrr] [drrr] 
    \ar [d]
    & \text{ }
    & \text{ }
    & \text{ }
    \\
    \text{Plot 1} 
    \ar [d]
    & 
    \text{Model $f(\mathbf x, \lambda_1)$} 
    %\ar [r]
    &
    \color{white}{\text{Plot 2} }
    %\ar [d]
    & 
    \color{white}{\text{Model $f(\mathbf x, \lambda_2)$} }
    \\
    \text{Labels $\mathbf y_1$}       
    \ar [d]
    %\ar [rr]
    %\ar [rru]
    &
    &
    \color{white}{\text{Labels $\mathbf y_2$}}
    %\ar [d]
    \\
    \text{Parameter $\lambda_1$} 
    \ar `r[ruu] [ruu]
    & \text{ }
    & 
    \color{white}{\text{Parameter $\lambda_2$}}
    %\ar `r[ruu] [ruu]
  }
  \end{displaymath}
\end{frame}

\begin{frame}
  \frametitle{Supervised, interactive genomic segmentation}
  Plot data, model, and labels.
  \small
  \begin{displaymath}
  \xymatrix{
    \text{Data $\mathbf x$}
    \ar `[r] [dr] 
    \ar `r[rr] [drr] 
    %\ar `r[rrr] [drrr] 
    \ar [d]
    & \text{ }
    & \text{ }
    & \text{ }
    \\
    \text{Plot 1} 
    \ar [d]
    & 
    \text{Model $f(\mathbf x, \lambda_1)$} 
    \ar [r]
    &
    \text{Plot 2} 
    %\ar [d]
    & 
    \color{white}{\text{Model $f(\mathbf x, \lambda_2)$} }
    \\
    \text{Labels $\mathbf y_1$}       
    \ar [d]
    %\ar [rr]
    \ar [rru]
    &
    &
    \color{white}{\text{Labels $\mathbf y_2$}}
    %\ar [d]
    \\
    \text{Parameter $\lambda_1$} 
    \ar `r[ruu] [ruu]
    & \text{ }
    & 
    \color{white}{\text{Parameter $\lambda_2$}}
    %\ar `r[ruu] [ruu]
  }
  \end{displaymath}
\end{frame}

\begin{frame}
  \frametitle{Supervised, interactive genomic segmentation}
  Add/delete labels based on plotted signal/noise.
  \small
  \begin{displaymath}
  \xymatrix{
    \text{Data $\mathbf x$}
    \ar `[r] [dr] 
    \ar `r[rr] [drr] 
    %\ar `r[rrr] [drrr] 
    \ar [d]
    & \text{ }
    & \text{ }
    & \text{ }
    \\
    \text{Plot 1} 
    \ar [d]
    & 
    \text{Model $f(\mathbf x, \lambda_1)$} 
    \ar [r]
    &
    \text{Plot 2} 
    \ar [d]
    & 
    \color{white}{\text{Model $f(\mathbf x, \lambda_2)$} }
    \\
    \text{Labels $\mathbf y_1$}       
    \ar [d]
    \ar [rr]
    \ar [rru]
    &
    &
    \text{Labels $\mathbf y_2$}
    %\ar [d]
    \\
    \text{Parameter $\lambda_1$} 
    \ar `r[ruu] [ruu]
    & \text{ }
    & 
    \color{white}{\text{Parameter $\lambda_2$}}
    %\ar `r[ruu] [ruu]
  }
  \end{displaymath}
\end{frame}

\begin{frame}
  \frametitle{Supervised, interactive genomic segmentation}
  Compute a better parameter.
  \small
  \begin{displaymath}
  \xymatrix{
    \text{Data $\mathbf x$}
    \ar `[r] [dr] 
    \ar `r[rr] [drr] 
    %\ar `r[rrr] [drrr] 
    \ar [d]
    & \text{ }
    & \text{ }
    & \text{ }
    \\
    \text{Plot 1} 
    \ar [d]
    & 
    \text{Model $f(\mathbf x, \lambda_1)$} 
    \ar [r]
    &
    \text{Plot 2} 
    \ar [d]
    & 
    \color{white}{\text{Model $f(\mathbf x, \lambda_2)$} }
    \\
    \text{Labels $\mathbf y_1$}       
    \ar [d]
    \ar [rr]
    \ar [rru]
    &
    &
    \text{Labels $\mathbf y_2$}
    \ar [d]
    \\
    \text{Parameter $\lambda_1$} 
    \ar `r[ruu] [ruu]
    & \text{ }
    & \text{Parameter $\lambda_2$}
    %\ar `r[ruu] [ruu]
  }
  \end{displaymath}
\end{frame}


\begin{frame}
  \frametitle{Supervised, interactive genomic segmentation}
  Compute a better model.
  \small
  \begin{displaymath}
  \xymatrix{
    \text{Data $\mathbf x$}
    \ar `[r] [dr] 
    \ar `r[rr] [drr] 
    \ar `r[rrr] [drrr] 
    \ar [d]
    & \text{ }
    & \text{ }
    & \text{ }
    \\
    \text{Plot 1} 
    \ar [d]
    & 
    \text{Model $f(\mathbf x, \lambda_1)$} 
    \ar [r]
    &
    \text{Plot 2} 
    \ar [d]
    & 
    \text{Model $f(\mathbf x, \lambda_2)$} 
    \\
    \text{Labels $\mathbf y_1$}       
    \ar [d]
    \ar [rr]
    \ar [rru]
    &
    &
    \text{Labels $\mathbf y_2$}
    \ar [d]
    \\
    \text{Parameter $\lambda_1$} 
    \ar `r[ruu] [ruu]
    & \text{ }
    & \text{Parameter $\lambda_2$}
    \ar `r[ruu] [ruu]
  }
  \end{displaymath}
\end{frame}


\begin{frame}
  \frametitle{Test error decreases as profiles are labeled}
  Hocking \textit{et al}. SegAnnDB: interactive web-based genomic
  segmentation. Bioinformatics (2014).
  \begin{center}
    \input{figure-test-error-decreases}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{Summary of contributions to
    DNA copy number analysis}
  \begin{center}
  \begin{tabular}{c|c|c}
    & \textbf{unsupervised} & \textbf{supervised}\\
    Evaluation: & qualitative &  quantitative \\
    Input: profile $\mathbf x$ + & parameters $\lambda$ & labels $\mathbf y$ \\
    \hline
    \textbf{non-interactive}
    & plot $\mathbf x$ & plot $\mathbf x, \mathbf y$\\
    fit one model
    & default parameters $\lambda$ & trained parameters $\lambda$ \\
    & e.g. DNAcopy & BMC'13, ICML'13\\
    \hline
    \textbf{interactive}
    & plot $\mathbf x, f(\mathbf x, \lambda)$ 
    & plot $\mathbf x, \mathbf y, f(\mathbf x, \lambda)$\\
    plot, update model 
    & manually tuned $\lambda$ & iterative $\lambda$ training\\
    & e.g. CGHweb  & Bioinfo'14
  \end{tabular}
  \end{center}
  \begin{description}
  % \item[2004-now] dozens of \textbf{unsupervised} models that can be
  %   \textbf{tweaked} e.g. GLAD, DNAcopy, fused lasso, cghseg, PELT.
  % \item[2009-2010] \textbf{No model $f$}! Breakpoint labels recorded
  %   by typing 0/1 in Excel spreadsheets (Janoueix-Lerosey,
  %   Schleiermacher, \textit{et al.} J Clinical Oncology).
  \item[BMC'13] \textbf{Non-interactive, supervised, single-parameter}.
    Learning smoothing models of copy number profiles... 
    BMC Bioinformatics, Hocking \textit{et al}.
  \item[ICML'13] \textbf{Non-interactive, supervised,
      multi-parameter}.  
    Learning sparse penalties... Rigaill \textit{et al}.
  \item[Bioinfo'14] \textbf{Interactive, supervised, multi-parameter}.
    SegAnnDB..., Bioinformatics, Hocking \textit{et al}.
  \end{description}
\end{frame}

\section{Supervised ChIP-seq peak detection}

\begin{frame}
  \frametitle{Chromatin immunoprecipitation sequencing (ChIP-seq)}
  Analysis of DNA-protein interactions.

  \includegraphics[width=\textwidth]{Chromatin_immunoprecipitation_sequencing_wide.png}

  Source: ``ChIP-sequencing,'' Wikipedia.
\end{frame}

\begin{frame}
  \frametitle{Data downloaded from Epigenomes Portal}
  \includegraphics[width=2.5in]{screenshot-samples}
\end{frame}

\begin{frame}
  \frametitle{Problem: find peaks and differences in several
    samples}
  \includegraphics[width=\textwidth]{screenshot-ucsc-edited}

  Peaks detected by Model-based analysis of ChIP-Seq (MACS), Zhang et
  al, 2008.
\end{frame}

\begin{frame}
  \frametitle{Existing unsupervised peak detection algorithms}
  \begin{itemize}
  \item Model-based analysis of ChIP-Seq (MACS), Zhang et al, 2008.
  \item SICER, Zang et al, 2009.
  \item HOMER findPeaks, Heinz et al, 2010.
  \item RSEG, Song and Smith, 2011.
  \item Histone modifications in cancer (HMCan), Ashoor et al, 2013.
  \item ... dozens of others.
  \end{itemize}
  Two big questions: how to choose the best...
  \begin{itemize}
  \item ...algorithm?
  \item ...parameters?
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{How to choose model parameters?}
\scriptsize
19 parameters for Model-based analysis of ChIP-Seq (MACS), Zhang et al, 2008.
\begin{verbatim}
  [-g GSIZE]
  [-s TSIZE] [--bw BW] [-m MFOLD MFOLD] [--fix-bimodal]
  [--nomodel] [--extsize EXTSIZE | --shiftsize SHIFTSIZE]
  [-q QVALUE | -p PVALUE | -F FOLDENRICHMENT] [--to-large]
  [--down-sample] [--seed SEED] [--nolambda]
  [--slocal SMALLLOCAL] [--llocal LARGELOCAL]
  [--shift-control] [--half-ext] [--broad]
  [--broad-cutoff BROADCUTOFF] [--call-summits]
\end{verbatim}
10 parameters for Histone modifications in cancer (HMCan),
Ashoor et al, 2013. 
\begin{verbatim}
minLength 145
medLength 150
maxLength 155
smallBinLength 50
largeBinLength 100000
pvalueThreshold 0.01
mergeDistance 200
iterationThreshold 5
finalThreshold 0
maxIter 20
\end{verbatim}
Not feasible to use grid search in 10 dimensions ($3^{10} = 59,049$).
\end{frame}

\begin{frame}
  \frametitle{Unsupervised, non-interactive ChIP-seq data analysis}

  Existing ChIP-seq peak detectors.
  \begin{displaymath}
  \xymatrix{
    \text{Data $\mathbf x$}
    \ar `[r] [dr] 
    %\ar [d]
    & \text{ }
    \\
    \color{white}{\text{Plot} }
    %\ar [d]
    & 
    \text{Model $f(\mathbf x, \lambda)$} 
    \\
    \color{white}{\text{Labels $\mathbf y$}       }
    %\ar [d]
    \\
    \text{Parameter $\lambda$} 
    \ar `r[ruu] [ruu]
    & \text{ }
  }
  \end{displaymath}
\end{frame}

\begin{frame}
  \frametitle{Supervised, non-interactive ChIP-seq data analysis}
  Plot ChIP-seq profile $\mathbf x$, make labels $\mathbf y$, use to
  train parameter $\lambda$.
  \begin{displaymath}
  \xymatrix{
    \text{Data $\mathbf x$}
    \ar `[r] [dr] 
    \ar [d]
    & \text{ }
    \\
    \text{Plot} 
    \ar [d]
    & 
    \text{Model $f(\mathbf x, \lambda)$} 
    \\
    \text{Labels $\mathbf y$}       
    \ar [d]
    \\
    \text{Parameter $\lambda$} 
    \ar `r[ruu] [ruu]
    & \text{ }
  }
  \end{displaymath}
\end{frame}

\begin{frame}
  \frametitle{Peak H3K4me3 profiles with manually annotated regions}
  \includegraphics[width=\textwidth]{figure-macs-default-4samples-just-regions}

  Determined by visual inspection on
  \href{http://ucscbrowser.genap.ca/cgi-bin/hgTracks?db=hg19\&position=chr11:118080000-118130000}{ucscbrowser.genap.ca}
\end{frame}

\begin{frame}
  \frametitle{Peak H3K4me3 profiles, macs default model}
  \includegraphics[width=\textwidth]{figure-macs-default-4samples-with-peaks}

  How many errors?
\end{frame}

\begin{frame}
  \frametitle{Peak H3K4me3 profiles, macs default model}
  \includegraphics[width=\textwidth]{figure-macs-default-4samples}

  3 false positives, 2 false negatives.
\end{frame}

\begin{frame}
  \frametitle{Peak H3K4me3 profiles, macs trained model}
  \includegraphics[width=\textwidth]{figure-macs-4samples}

  1 false positive, 3 false negatives.
\end{frame}


\begin{frame}
  \frametitle{Benchmark: 7 manually labeled ChIP-seq data sets}
  
  \includegraphics[width=\textwidth]{figure-several-annotators}

  \url{http://cbio.ensmp.fr/~thocking/chip-seq-chunk-db/}
  \begin{itemize}
  \item 4 annotators (AM, TDH, PGP, XJ).
  \item 8 cell types.
  \item 37 annotated H3K4me3 profiles (sharp peaks).
  \item 29 annotated H3K36me3 profiles (broadly enriched domains).
  \item 12,826 annotated regions in total.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{ROC curves for train error of unsupervised models}
    Reference: Hocking \textit{et al.} Visual annotations and a
  supervised learning approach for evaluating and calibrating ChIP-seq
  peak detectors (arXiv:1409.6209).

  \includegraphics[width=0.9\textwidth]{figure-roc}

  % Rye \textit{et al.} 2011 also observed many false positives:
  % ``$>80\%$ of these peaks could be manually filtered out by visual
  % inspection alone, without using additional background data''

  Can we do better with supervised learning?
\end{frame}

\begin{frame}
  \frametitle{PeakSeg: state-of-the-art peak detection accuracy for
    both sharp H3K4me3 and broad H3K36me3 profiles}
  Reference: Hocking \textit{et al.} PeakSeg: peak detection via
  constrained optimal segmentation. NIPS 2014 workshop on machine
  learning in computational biology.

  \vskip 0.1cm

  Two main ideas: 

  \begin{itemize}
  \item Optimal segmentation: search for the best peaks, out of
    \alert<2>{all possible} peak start/end locations.\\
    (for example, no fixed bin size)
  \item Supervised learning: max-margin interval regression learns a
    \alert<2>{multi-parameter} penalty function using the labels
    $\mathbf y$ and
    gradient descent (Rigaill \textit{et al.} ICML 2013).\\
    (vs intractable grid search in unsupervised algorithms)
  \end{itemize}
  
\end{frame}

\begin{frame}
  \frametitle{Test error of 3 peak detectors on 6 sharp profiles}
  \includegraphics[width=\textwidth]{figure-dp-peaks-train-2}
\end{frame}

\begin{frame}
  \frametitle{Test error of 3 peak detectors on 6 broad profiles}
  \includegraphics[width=\textwidth]{figure-dp-peaks-train-1}
\end{frame}

\begin{frame}
  \frametitle{State-of-the-art peak detection on both sharp H3K4me3
    and broad H3K36me3 data sets}
  Interactive version with test ROC curves:

  \small

  \url{http://cbio.ensmp.fr/~thocking/figure-dp-peaks-interactive}

  \includegraphics[width=\textwidth]{figure-dp-peaks-regression-dots}

  Caveats: 
  \begin{itemize}
  \item With few training labels $\mathbf y$ (H3K36me3\_TDH data),\\
    PeakSeg sometimes less accurate than hmcan.broad.
  \item Current implementation slow for whole genome\\
    (several days vs several hours for macs).
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Summary of past and future work in supervised ChIP-seq
    peak detection}
  \begin{description}
  \item[2011] \textbf{Unsupervised training, labels for testing.}\\
    Rye et al. Manually labeled binding sites and visual
    peaks for 3
    transcription factors.
  \item[2014] \textbf{Single-parameter model training and evaluation.}\\
    Hocking et al. arXiv:1409.6209. Manually labeled visual
    peaks for 2 histone marks, 4 different annotators.\\
    \textbf{Multi-parameter model training}\\
    Hocking et al. NIPS Computational Biology workshop.
    PeakSeg: peak detection via constrained optimal segmentation.
  \item[2015] Supervised, interactive ChIP-seq peak detection?
  \end{description}
\end{frame}

\begin{frame} 
  \frametitle{Advantages of supervised learning}
  Creating data sets $\mathbf x$ with labels $\mathbf y$ is important for
  \begin{description}
  \item[short-term] quantitative evaluation, big data sets.
  \item[long-term] cross-discipline collaboration!
    \begin{description}
    \item[statisticians/modelers] get better evaluation
    metrics.
    \item[biologists/annotators] get
    better models of big data.
    \end{description}
  \end{description}

  Can we make labels/supervised approaches for...
  \begin{description}
  \item[segmentation] breakpoint/copy number/peaks (this work).
  \item[clustering] pairs that should join (or not)?
  \item[regression] variables/genes that are important (or not)?
  \item[diff expression] genes that are up/down (or not)?
  \end{description}
\end{frame}

\begin{frame}
  \frametitle{Thank you!}
  Write me at \alert{\texttt{toby.hocking@mail.mcgill.ca}} to collaborate!

  \vskip 1cm

  Source code for slides online!\\
  \small
  \url{https://github.com/tdhock/supervised-interactive-slides}
  \vskip 1cm

  Supplementary slides appear after this one.

\end{frame}

\end{document}
